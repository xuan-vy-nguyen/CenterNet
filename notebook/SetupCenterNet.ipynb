{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "SetupCenterNet.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z65XrCmnsQL8",
        "colab_type": "text"
      },
      "source": [
        "Đến thư mục chính. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x1lvPweQqHbC",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "4561275f-2d8b-4877-bc67-41626c14347d"
      },
      "source": [
        "ROOT='/content'\n",
        "%cd $ROOT"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ngpMhtARiw-Z",
        "colab_type": "text"
      },
      "source": [
        "# Bước 1 - Cài đặt CenterNet\n",
        "- Vào link github của [CenterNet](https://github.com/xingyizhou/CenterNet)\n",
        "- Đi sâu vào đọc [hướng dẫn cài đặt](https://github.com/xingyizhou/CenterNet/blob/master/readme/INSTALL.md) của link trên\n",
        "- Để việc cài đặt nhanh hơn thì em sử dụng source đã config của CenterNet."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y1gy7fhVjKRh",
        "colab_type": "text"
      },
      "source": [
        "##Step-1 Cài torch & torchvision"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z89xUJCRSEoJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!pip install -U torch==1.4 torchvision==0.5 -f https://download.pytorch.org/whl/cu101/torch_stable.html\\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rv3yqOwAmeO-",
        "colab_type": "text"
      },
      "source": [
        "Tất cả đều ngon lành! Vậy là xong Step1"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q7CUzlSXmtsv",
        "colab_type": "text"
      },
      "source": [
        "##Step-2 Cài COCOAPI"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e_BMLH9mp7y4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "COCOAPI = '/content/cocoapi'\n",
        "!git clone https://github.com/cocodataset/cocoapi.git $COCOAPI\n",
        "%cd $COCOAPI/PythonAPI"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aGuVRGYAxUZI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "%%capture\n",
        "!make"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-4p4AXrExWVU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "%%capture\n",
        "!python setup.py install --user"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ztAd6VNDsugu",
        "colab_type": "text"
      },
      "source": [
        "## Step-3 Clone Repo của CenterNet & Cài những thứ cần thiết"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i_GMXExXtfpw",
        "colab_type": "text"
      },
      "source": [
        "Nếu cài trên máy thì cần cài Cython trước"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Dp-gSgIvsyUp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "%cd $ROOT\n",
        "CenterNet_ROOT = '/content/CenterNet'\n",
        "!git clone https://github.com/xuan-vy-nguyen/CenterNet.git $CenterNet_ROOT\n",
        "%cd $CenterNet_ROOT\n",
        "!pip install -r requirements.txt"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5EFyltyEyEj_",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "e596e8e0-4621-483b-a9ba-95d986f6baa4"
      },
      "source": [
        "%cd $CenterNet_ROOT/src/lib/external"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/CenterNet/src/lib/external\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nK4mT3KhyISk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "%%capture\n",
        "!python setup.py build_ext --inplace"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i7MIMhditDxT",
        "colab_type": "text"
      },
      "source": [
        "##Step-4 Build DCNv2"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jq7XOZNGP4Pg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "%cd $CenterNet_ROOT/src/lib/models/networks\n",
        "!rm -rf DCNv2\n",
        "!git clone https://github.com/CharlesShang/DCNv2\n",
        "%cd DCNv2\n",
        "!python setup.py build develop"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UtVZOJ1oRTZt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!./make.sh"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aMyX3DnkjOaa",
        "colab_type": "text"
      },
      "source": [
        "# Bước 2 - Chỉnh tham số để nhận Dataset & các chi tiết khác"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5MjQTgD4hq41",
        "colab_type": "text"
      },
      "source": [
        "- Bước này chỉ áp dụng cho các source sử dụng code của tác giả gốc [CenterNet](https://github.com/xingyizhou/CenterNet).\n",
        "- Để cho nhanh thì có thể xài repo của em đã chỉnh sẵn mà chạy thôi (chỉ áp dụng cho AI City Challenge).\n",
        "- Các dataset khác thì phải đọc [Document](https://docs.google.com/document/d/15YOLLdwbuWffrNhg0BsR6aDBmBMS3Kh2J4y-Y0AKBpE/edit) này (của Phạm Trọng Thắng), nội dung ghi rất rõ cách cài đặt CenterNet & cài đặt tham số để nhận dataset.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VSNKL2FPjUCU",
        "colab_type": "text"
      },
      "source": [
        "# Bước 3 - Tải Dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AMkzCYWfmdn4",
        "colab_type": "text"
      },
      "source": [
        "- Link tải dataset [đây](https://drive.google.com/open?id=1xFcfOEfAXjjzdrZbH3glOxv0rHIne8H7)\n",
        "- Link tải label cho dataset [đây](https://drive.google.com/file/d/1SWsjrSNaRp3CVe9h3Fu41ezkvXcGPy0_/view?usp=sharing)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2y0ft5cSkil_",
        "colab_type": "text"
      },
      "source": [
        "1. Mọi người tạo trong CenterNet/data thư mục abc, abc/images chỉ chứa toàn ảnh, label chỉ chứa 2 file label.\n",
        "2. Sau khi tạo xong thì CenterNet/data nên có cấu trúc dạng như sau: \n",
        "- abc\n",
        "- + images\n",
        "- + + (1000 ảnh)\n",
        "- + label\n",
        "- + + instances_val_car.json\n",
        "- + + instances_train_car.json"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Vu8Uu6lomABp",
        "colab_type": "text"
      },
      "source": [
        "Do drive của em có sẵn nên chỉ cần copy qua :v"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K6g1mfZ4khp7",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "4187eaac-7fd9-4daf-bd69-644bf14500cd"
      },
      "source": [
        "!mkdir '/content/CenterNet/data/abc/images'\n",
        "!mkdir '/content/CenterNet/data/abc/labels'\n",
        "%cd '/content/CenterNet/data/abc'\n",
        "!cp -r '/content/drive/My Drive/detector/CenterNet/data/abc/images' ."
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "mkdir: cannot create directory ‘/content/CenterNet/data/abc/images’: File exists\n",
            "/content/CenterNet/data/abc\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l6TCJdkcsnuZ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "1abe400c-e959-43ad-a244-63cde5f2ad1c"
      },
      "source": [
        "# kiểm tra xem đủ ảnh trong folder chưa\n",
        "import os, os.path\n",
        "# path joining version for other paths\n",
        "DIR = '/content/CenterNet/data/abc/images'\n",
        "print(len([name for name in os.listdir(DIR) if os.path.isfile(os.path.join(DIR, name))]))"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EF4aTcHHjaWJ",
        "colab_type": "text"
      },
      "source": [
        "# Bước 4 - Training"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "In8QW9yYq8rm",
        "colab_type": "text"
      },
      "source": [
        "Tham số:\n",
        "- exp_id: thư mục lưu log và chưa model.pth\n",
        "- arch: kiến trúc backbone mà mình sẽ sử dụng (AI City Challenge thì nên xài dla34).\n",
        "- batch_size: số dữ liệu trong 1 batch (nếu tràn RAM thì giảm cái này xuống).\n",
        "- num_workder: số luồng load dữ liệu lên RAM/GPU.\n",
        "- num_epochs: số lần train dữ liệu."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O6owu3XwotWr",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 474
        },
        "outputId": "9cabf6fa-4564-49da-e5da-90aedaeedbe3"
      },
      "source": [
        "%cd $CenterNet_ROOT/src\n",
        "!python main.py ctdet --exp_id abc_dla_34 --arch dla_34 --batch_size 32 --num_workers 2 --num_epochs 2"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/CenterNet/src\n",
            "Fix size testing.\n",
            "training chunk_sizes: [32]\n",
            "The output will be saved to  /content/CenterNet/src/lib/../../exp/ctdet/abc_dla_34\n",
            "heads {'hm': 3, 'wh': 2, 'reg': 2}\n",
            "Namespace(K=100, aggr_weight=0.0, agnostic_ex=False, arch='dla_34', aug_ddd=0.5, aug_rot=0, batch_size=32, cat_spec_wh=False, center_thresh=0.1, chunk_sizes=[32], data_dir='/content/CenterNet/src/lib/../../data', dataset='coco', debug=0, debug_dir='/content/CenterNet/src/lib/../../exp/ctdet/abc_dla_34/debug', debugger_theme='white', demo='', dense_hp=False, dense_wh=False, dep_weight=1, dim_weight=1, down_ratio=4, eval_oracle_dep=False, eval_oracle_hm=False, eval_oracle_hmhp=False, eval_oracle_hp_offset=False, eval_oracle_kps=False, eval_oracle_offset=False, eval_oracle_wh=False, exp_dir='/content/CenterNet/src/lib/../../exp/ctdet', exp_id='abc_dla_34', fix_res=True, flip=0.5, flip_test=False, gpus=[0], gpus_str='0', head_conv=256, heads={'hm': 3, 'wh': 2, 'reg': 2}, hide_data_time=False, hm_hp=True, hm_hp_weight=1, hm_weight=1, hp_weight=1, input_h=512, input_res=512, input_w=512, keep_res=False, kitti_split='3dop', load_model='', lr=0.000125, lr_step=[90, 120], master_batch_size=32, mean=array([[[0.40789655, 0.44719303, 0.47026116]]], dtype=float32), metric='loss', mse_loss=False, nms=False, no_color_aug=False, norm_wh=False, not_cuda_benchmark=False, not_hm_hp=False, not_prefetch_test=False, not_rand_crop=False, not_reg_bbox=False, not_reg_hp_offset=False, not_reg_offset=False, num_classes=3, num_epochs=2, num_iters=-1, num_stacks=1, num_workers=2, off_weight=1, output_h=128, output_res=128, output_w=128, pad=31, peak_thresh=0.2, print_iter=0, rect_mask=False, reg_bbox=True, reg_hp_offset=True, reg_loss='l1', reg_offset=True, resume=False, root_dir='/content/CenterNet/src/lib/../..', rot_weight=1, rotate=0, save_all=False, save_dir='/content/CenterNet/src/lib/../../exp/ctdet/abc_dla_34', scale=0.4, scores_thresh=0.1, seed=317, shift=0.1, skip_frame=0, std=array([[[0.2886383 , 0.27408165, 0.27809834]]], dtype=float32), task='ctdet', test=False, test_scales=[1.0], trainval=False, val_intervals=5, vis_thresh=0.3, wh_weight=0.1)\n",
            "Creating model...\n",
            "Setting up data...\n",
            "==> initializing abc 2017 test data.\n",
            "loading annotations into memory...\n",
            "Done (t=0.01s)\n",
            "creating index...\n",
            "index created!\n",
            "Loaded test 200 samples\n",
            "==> initializing abc 2017 train data.\n",
            "loading annotations into memory...\n",
            "Done (t=0.03s)\n",
            "creating index...\n",
            "index created!\n",
            "Loaded train 799 samples\n",
            "Starting training...\n",
            "early stop status = 0/5\n",
            "\u001b[?25lctdet/abc_dla_34/usr/local/lib/python3.6/dist-packages/torch/nn/_reduction.py:43: UserWarning: size_average and reduce args will be deprecated, please use reduction='sum' instead.\n",
            "  warnings.warn(warning.format(ret))\n",
            "\u001b[Kctdet/abc_dla_34 |########                        | train: [1][5/24]|Tot: 0:00:30 |ETA: 0:01:42 |loss 6.0455 |hm_loss 5.0408 |wh_loss 6.5548 |off_loss 0.3492 |Data 0.001s(0.513s) |Net 5.055s"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "45RkLX17idg8",
        "colab_type": "text"
      },
      "source": [
        "# Bước 5 - Testing\n",
        "Dùng để xem IoU các các thông số của model vừa train được trên tập dataset."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E6wvcqnTq2X_",
        "colab_type": "text"
      },
      "source": [
        "- exp_id - trỏ đến thư mục chứa model. Nên = exp_id ở trên nếu xài chính model đó để test.\n",
        "- arch: kiến trúc backbone\n",
        "- load_model: đường dẫn đến model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UcAexG1uif57",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 632
        },
        "outputId": "145a7c4a-24da-47a8-cea0-79f77f412c0e"
      },
      "source": [
        "!python test.py ctdet --exp_id abc_dla_34 --arch dla_34 --load_model ../exp/ctdet/abc_dla_34/model_best.pth --trainval"
      ],
      "execution_count": 64,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Fix size testing.\n",
            "training chunk_sizes: [32]\n",
            "The output will be saved to  /content/CenterNet/src/lib/../../exp/ctdet/abc_dla_34\n",
            "heads {'hm': 3, 'wh': 2, 'reg': 2}\n",
            "Namespace(K=100, aggr_weight=0.0, agnostic_ex=False, arch='dla_34', aug_ddd=0.5, aug_rot=0, batch_size=32, cat_spec_wh=False, center_thresh=0.1, chunk_sizes=[32], data_dir='/content/CenterNet/src/lib/../../data', dataset='coco', debug=0, debug_dir='/content/CenterNet/src/lib/../../exp/ctdet/abc_dla_34/debug', debugger_theme='white', demo='', dense_hp=False, dense_wh=False, dep_weight=1, dim_weight=1, down_ratio=4, eval_oracle_dep=False, eval_oracle_hm=False, eval_oracle_hmhp=False, eval_oracle_hp_offset=False, eval_oracle_kps=False, eval_oracle_offset=False, eval_oracle_wh=False, exp_dir='/content/CenterNet/src/lib/../../exp/ctdet', exp_id='abc_dla_34', fix_res=True, flip=0.5, flip_test=False, gpus=[0], gpus_str='0', head_conv=256, heads={'hm': 3, 'wh': 2, 'reg': 2}, hide_data_time=False, hm_hp=True, hm_hp_weight=1, hm_weight=1, hp_weight=1, input_h=512, input_res=512, input_w=512, keep_res=False, kitti_split='3dop', load_model='../exp/ctdet/abc_dla_34/model_best.pth', lr=0.000125, lr_step=[90, 120], master_batch_size=32, mean=array([[[0.40789655, 0.44719303, 0.47026116]]], dtype=float32), metric='loss', mse_loss=False, nms=False, no_color_aug=False, norm_wh=False, not_cuda_benchmark=False, not_hm_hp=False, not_prefetch_test=False, not_rand_crop=False, not_reg_bbox=False, not_reg_hp_offset=False, not_reg_offset=False, num_classes=3, num_epochs=140, num_iters=-1, num_stacks=1, num_workers=4, off_weight=1, output_h=128, output_res=128, output_w=128, pad=31, peak_thresh=0.2, print_iter=0, rect_mask=False, reg_bbox=True, reg_hp_offset=True, reg_loss='l1', reg_offset=True, resume=False, root_dir='/content/CenterNet/src/lib/../..', rot_weight=1, rotate=0, save_all=False, save_dir='/content/CenterNet/src/lib/../../exp/ctdet/abc_dla_34', scale=0.4, scores_thresh=0.1, seed=317, shift=0.1, skip_frame=0, std=array([[[0.2886383 , 0.27408165, 0.27809834]]], dtype=float32), task='ctdet', test=False, test_scales=[1.0], trainval=True, val_intervals=100000000, vis_thresh=0.3, wh_weight=0.1)\n",
            "==> initializing abc 2017 test data.\n",
            "loading annotations into memory...\n",
            "Done (t=0.01s)\n",
            "creating index...\n",
            "index created!\n",
            "Loaded test 200 samples\n",
            "Creating model...\n",
            "loaded ../exp/ctdet/abc_dla_34/model_best.pth, epoch 5\n",
            "\u001b[Kabc_dla_34 |################################| [199/200]|Tot: 0:00:11 |ETA: 0:00:01 |tot 0.024s (0.027s) |load 0.000s (0.000s) |pre 0.000s (0.000s) |net 0.021s (0.022s) |dec 0.001s (0.001s) |post 0.002s (0.003s) |merge 0.000s (0.000s) \n",
            "Loading and preparing results...\n",
            "DONE (t=0.09s)\n",
            "creating index...\n",
            "index created!\n",
            "Running per image evaluation...\n",
            "Evaluate annotation type *bbox*\n",
            "DONE (t=4.20s).\n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.18s).\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.147\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.398\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.068\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.054\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.162\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.227\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.050\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.164\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.200\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.134\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.221\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.287\n",
            "\u001b[?25h"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0i9j-f6PjciQ",
        "colab_type": "text"
      },
      "source": [
        "# Bước 5 - Inference"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GwypPIQMiGog",
        "colab_type": "text"
      },
      "source": [
        "Tạo thư mục input chứa video cần boundingbox, sau đó đẩy hết video cần inference vào đó (lưu ý, nên là chấm duối .mp4, nếu khác thì vào demo_video.py để sửa lại)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Jiwz-OznqDc6",
        "colab_type": "text"
      },
      "source": [
        "Dataset của AICity Challenge track1 được lưu ở [đây](https://drive.google.com/open?id=1-1BmCScH54xz6-fB693EMlWwJU99LUNI), nếu mọi người muốn sử dụng thì đưa nó vào thư mục input"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wIZe8ULAXIlK",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "72176f64-56b0-4ab0-9066-74afafd8d9b0"
      },
      "source": [
        "%cd $ROOT\n",
        "!mkdir input\n",
        "!cp '/content/drive/My Drive/My_AICity2020/My_Track1/AIC20_track1/Dataset_A/cam_1.mp4' input # em test 1 video cho nó lẹ"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6iPPeMbNfM7G",
        "colab_type": "text"
      },
      "source": [
        "Ở bước này mọi người có 2 lựa chọn:\n",
        "1. Đã tự train -> sử dụng model của mình để inference\n",
        "2. Chưa train -> sử dụng model của em đã train sẵn để inference."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i1pxTB8-fmBN",
        "colab_type": "text"
      },
      "source": [
        "Đây là [link](https://drive.google.com/file/d/1_e9Aa93B87rYJzzWKlEu9O0ZE8u3DWqg/view?usp=sharing) pretrained model của em, mọi người có thể add nó vào thư mục CenterNet/models (Code bên dưới là do em có sẵn file trong drive nên copy qua cho lẹ)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5Q3kgzqj17RW",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "04fec422-4f9d-441f-89b0-60c9186c542c"
      },
      "source": [
        "%cd $CenterNet_ROOT/models\n",
        "!cp '/content/drive/My Drive/My_AICity2020/My_Track1/dla_34_200e.pth' ./"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/CenterNet/models\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gjT90LB1f8gV",
        "colab_type": "text"
      },
      "source": [
        "Nên xóa đi thư mục chưa kết quả của lần inference trước"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RFNyin0LeUd7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!rm -rf $ROOT/CenterNet/visualization/dla_34\n",
        "!rm -rf $CenterNet_ROOT/Detection/*"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PBkyMxR_gEbB",
        "colab_type": "text"
      },
      "source": [
        "Và chạy inference\n",
        "- Tham số demo dùng để nhập input của mình là gì (dạng folder chứa video).\n",
        "- Tham số load_model dùng để trỏ đường dẫn đến model cần dùng để inference"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Cp-bVtEc2xL4",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 819
        },
        "outputId": "c3f2bbdd-1f31-4b13-f953-52a348cf0d12"
      },
      "source": [
        "%cd  $CenterNet_ROOT/src\n",
        "!python demo_video.py ctdet --demo /content/input --load_model ../exp/ctdet/abc_dla_34/model_best.pth"
      ],
      "execution_count": 66,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/CenterNet/src\n",
            "Fix size testing.\n",
            "training chunk_sizes: [32]\n",
            "The output will be saved to  /content/CenterNet/src/lib/../../exp/ctdet/default\n",
            "heads {'hm': 2, 'wh': 2, 'reg': 2}\n",
            "*skip_frame =  0\n",
            "Creating model...\n",
            "loaded ../exp/ctdet/abc_dla_34/model_best.pth, epoch 5\n",
            "Skip loading parameter hm.2.weight, required shapetorch.Size([2, 256, 1, 1]), loaded shapetorch.Size([3, 256, 1, 1]). If you see this, your model does not fully load the pre-trained weight. Please make sure you have correctly specified --arch xxx or set the correct --num_classes for your own dataset.\n",
            "Skip loading parameter hm.2.bias, required shapetorch.Size([2]), loaded shapetorch.Size([3]). If you see this, your model does not fully load the pre-trained weight. Please make sure you have correctly specified --arch xxx or set the correct --num_classes for your own dataset.\n",
            "  8% 253/3000 [00:13<02:27, 18.64it/s]Traceback (most recent call last):\n",
            "  File \"demo_video.py\", line 90, in <module>\n",
            "  File \"demo_video.py\", line 69, in demo\n",
            "    ret = detector.run(img)\n",
            "  File \"/content/CenterNet/src/lib/detectors/base_detector.py\", line 116, in run\n",
            "    output, dets, forward_time = self.process(images, return_time=True)\n",
            "  File \"/content/CenterNet/src/lib/detectors/ctdet.py\", line 30, in process\n",
            "    output = self.model(images)[-1]\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/torch/nn/modules/module.py\", line 532, in __call__\n",
            "    result = self.forward(*input, **kwargs)\n",
            "  File \"/content/CenterNet/src/lib/models/networks/pose_dla_dcn.py\", line 471, in forward\n",
            "    x = self.base(x)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/torch/nn/modules/module.py\", line 532, in __call__\n",
            "    result = self.forward(*input, **kwargs)\n",
            "  File \"/content/CenterNet/src/lib/models/networks/pose_dla_dcn.py\", line 290, in forward\n",
            "    x = getattr(self, 'level{}'.format(i))(x)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/torch/nn/modules/module.py\", line 532, in __call__\n",
            "    result = self.forward(*input, **kwargs)\n",
            "  File \"/content/CenterNet/src/lib/models/networks/pose_dla_dcn.py\", line 220, in forward\n",
            "    x = self.tree2(x1, children=children)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/torch/nn/modules/module.py\", line 532, in __call__\n",
            "    result = self.forward(*input, **kwargs)\n",
            "  File \"/content/CenterNet/src/lib/models/networks/pose_dla_dcn.py\", line 217, in forward\n",
            "    x = self.root(x2, x1, *children)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/torch/nn/modules/module.py\", line 532, in __call__\n",
            "    result = self.forward(*input, **kwargs)\n",
            "  File \"/content/CenterNet/src/lib/models/networks/pose_dla_dcn.py\", line 159, in forward\n",
            "    x = self.conv(torch.cat(x, 1))\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/torch/nn/modules/module.py\", line 532, in __call__\n",
            "    result = self.forward(*input, **kwargs)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/torch/nn/modules/conv.py\", line 345, in forward\n",
            "    return self.conv2d_forward(input, self.weight)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/torch/nn/modules/conv.py\", line 342, in conv2d_forward\n",
            "    self.padding, self.dilation, self.groups)\n",
            "KeyboardInterrupt\n",
            "  8% 253/3000 [00:13<02:30, 18.25it/s]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ixWy-DfRgKb7",
        "colab_type": "text"
      },
      "source": [
        "## Kêt quả\n",
        "0. Thời gian được in ra ở mục liền kề bên trên (do có xuất cả video nên nó sẽ chậm hơn source dùng cho AI City Challenge).\n",
        "1. Kết quả xuất ra có 2 dạng chính: bounding-box và video.\n",
        "2. Video được lưu ở thư mục visualization, thực ra nó chỉ dùng cho debug trong AI-City Challenge, vì CenterNet là 1 bước nhỏ trong đó. Muốn tắt việc sinh video để tăng tốc inference thì vào demo_video, tìm và xóa TUẦN TỰ các phần nằm giữa cặp dấu ###.\n",
        "3. Bounding-box có 2 dạng: .json và .pkl => Muốn sinh .json thì xài demo.py, còn .pkl thì xài demo_video.py.\n",
        "\n",
        "*Khuyên dùng demo_video.py*"
      ]
    }
  ]
}